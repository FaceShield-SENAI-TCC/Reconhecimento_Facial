"""
Servi√ßo de Reconhecimento Facial AJUSTADO para c√¢meras de qualidade inferior
"""

import logging
import time
import threading
import numpy as np
import cv2
import base64
import psycopg2
import psycopg2.extensions
from datetime import datetime
from deepface import DeepFace
from typing import Tuple, Optional, Dict, Any

logger = logging.getLogger(__name__)

class DatabaseConfig:
    """Configura√ß√µes do banco de dados PostgreSQL"""
    DB_NAME = "faceshild"
    DB_USER = "postgres"
    DB_PASSWORD = "root"
    DB_HOST = "localhost"
    DB_PORT = "5432"

class ModelConfig:
    """Configura√ß√µes do modelo de reconhecimento - VGG-Face AJUSTADO"""
    MODEL_NAME = "VGG-Face"

    # ‚úÖ THRESHOLD MAIS TOLERANTE
    DISTANCE_THRESHOLD = 0.65  # ‚úÖ AUMENTADO de 0.55 para 0.65 (mais tolerante)

    # ‚úÖ CONFIAN√áA M√çNIMA REDUZIDA
    MIN_CONFIDENCE_THRESHOLD = 0.6  # ‚úÖ REDUZIDO de 0.7 para 0.6

    MIN_FACE_SIZE = (80, 80)  # ‚úÖ REDUZIDO tamanho m√≠nimo

    # ‚úÖ DETECTOR MAIS TOLERANTE
    DETECTOR_BACKEND = "opencv"  # ‚úÖ Alterado para opencv (mais tolerante)

    EMBEDDING_DIMENSION = 2622

    # ‚úÖ PAR√ÇMETROS DE QUALIDADE REDUZIDOS
    MIN_SHARPNESS = 40  # ‚úÖ REDUZIDO de 80 para 40
    MIN_BRIGHTNESS = 30  # ‚úÖ REDUZIDO brilho m√≠nimo
    MAX_BRIGHTNESS = 220 # ‚úÖ AUMENTADO brilho m√°ximo

# ... (DatabaseMonitor mantido igual) ...

class FaceRecognitionService:
    """
    Servi√ßo principal de reconhecimento facial AJUSTADO
    """

    def __init__(self):
        self.facial_database = {}
        self.last_update = None
        self._db_config = DatabaseConfig()
        self._model_config = ModelConfig()
        self.database_monitor = DatabaseMonitor(self.load_facial_database)

        # Estat√≠sticas de reconhecimento
        self.recognition_stats = {
            'total_attempts': 0,
            'successful_auth': 0,
            'failed_auth': 0,
            'quality_rejections': 0
        }

    # ... (m√©todos de banco mantidos) ...

    def _calculate_sharpness(self, image):
        """Calcula nitidez da imagem - VERS√ÉO SIMPLIFICADA"""
        if image is None or image.size == 0:
            return 0
        try:
            small_img = cv2.resize(image, (100, 100))
            gray = cv2.cvtColor(small_img, cv2.COLOR_BGR2GRAY)
            return cv2.Laplacian(gray, cv2.CV_64F).var()
        except:
            return 0

    def _validate_face_quality(self, face_image: np.ndarray) -> Tuple[bool, str]:
        """
        ‚úÖ VALIDA√á√ÉO SIMPLIFICADA da qualidade da face
        """
        if face_image is None or face_image.size == 0:
            return False, "Imagem vazia"

        height, width = face_image.shape[:2]
        if height < self._model_config.MIN_FACE_SIZE[0] or width < self._model_config.MIN_FACE_SIZE[1]:
            return False, "Rosto muito pequeno"

        # Validar nitidez (mais tolerante)
        sharpness = self._calculate_sharpness(face_image)
        if sharpness < self._model_config.MIN_SHARPNESS:
            return False, f"Imagem um pouco borrada: {sharpness:.1f}"

        # ‚úÖ VALIDA√á√ÉO DE BRILHO SIMPLIFICADA
        try:
            gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            brightness = np.mean(gray)
            if brightness < self._model_config.MIN_BRIGHTNESS:
                return False, f"Brilho muito baixo: {brightness:.1f}"
            if brightness > self._model_config.MAX_BRIGHTNESS:
                return False, f"Brilho muito alto: {brightness:.1f}"
        except:
            # Se falhar na an√°lise, continua mesmo assim
            pass

        return True, f"Qualidade aceit√°vel: Sharp={sharpness:.1f}"

    def _extract_face_embedding(self, face_image: np.ndarray) -> Optional[np.ndarray]:
        """
        Extrai embedding facial com configura√ß√£o TOLERANTE
        """
        try:
            # ‚úÖ PR√â-PROCESSAMENTO SIMPLIFICADO
            try:
                # Tenta melhorar o contraste
                lab = cv2.cvtColor(face_image, cv2.COLOR_BGR2LAB)
                lab[:,:,0] = cv2.createCLAHE(clipLimit=1.0).apply(lab[:,:,0])  # ‚úÖ Clip reduzido
                processed_face = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            except:
                processed_face = face_image

            result = DeepFace.represent(
                img_path=processed_face,
                model_name=self._model_config.MODEL_NAME,
                detector_backend=self._model_config.DETECTOR_BACKEND,
                enforce_detection=False,
                align=False  # ‚úÖ Alinhamento desativado para performance
            )

            if result and isinstance(result, list) and "embedding" in result[0]:
                embedding = np.array(result[0]["embedding"], dtype=np.float32)

                if embedding.shape[0] != self._model_config.EMBEDDING_DIMENSION:
                    logger.error(f"Dimens√£o incorreta: {embedding.shape[0]}")
                    return None

                embedding_norm = np.linalg.norm(embedding)
                return embedding / embedding_norm if embedding_norm > 0 else None

            logger.warning("Nenhum embedding gerado")
            return None

        except Exception as e:
            logger.error(f"Falha na extra√ß√£o do embedding: {str(e)}")
            return None

    def _recognize_face(self, face_image: np.ndarray) -> Tuple[Optional[str], Optional[float], Optional[float]]:
        """
        Reconhecimento facial com par√¢metros TOLERANTES
        """
        try:
            captured_embedding = self._extract_face_embedding(face_image)
            if captured_embedding is None:
                return None, None, None

            best_match = None
            min_distance = float('inf')
            best_confidence = 0.0

            # Busca no banco de dados
            for user_key, user_data in self.facial_database.items():
                for db_embedding in user_data['embeddings']:
                    # Dist√¢ncia cosseno para VGG-Face
                    distance = 1 - np.dot(captured_embedding, db_embedding)

                    # ‚úÖ VALIDA√á√ÉO MAIS TOLERANTE
                    confidence = 1 - distance

                    if (distance < min_distance and
                        distance < self._model_config.DISTANCE_THRESHOLD and
                        confidence > self._model_config.MIN_CONFIDENCE_THRESHOLD):

                        min_distance = distance
                        best_match = user_key
                        best_confidence = confidence

            return best_match, min_distance, best_confidence

        except Exception as e:
            logger.error(f"Falha no reconhecimento: {str(e)}")
            return None, None, None

    def _decode_base64_image(self, image_data: str) -> Optional[np.ndarray]:
        """Decodifica imagem base64 para array numpy"""
        try:
            img_bytes = base64.b64decode(image_data)
            nparr = np.frombuffer(img_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            return image if image is not None and image.size > 0 else None
        except Exception as e:
            logger.error(f"Falha na decodifica√ß√£o: {str(e)}")
            return None

    def _detect_face(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        Detec√ß√£o de rostos MAIS TOLERANTE
        """
        try:
            detected_faces = DeepFace.extract_faces(
                img_path=image,
                detector_backend=self._model_config.DETECTOR_BACKEND,
                enforce_detection=False
            )

            if (detected_faces and len(detected_faces) > 0 and
                "facial_area" in detected_faces[0] and
                detected_faces[0].get('confidence', 0) > 0.5):  # ‚úÖ Confian√ßa m√≠nima reduzida
                return detected_faces[0]

            return None

        except Exception as e:
            logger.error(f"Falha na detec√ß√£o: {str(e)}")
            return None

    def process_face_login(self, image_data: str) -> Dict[str, Any]:
        """
        Processamento de login MAIS TOLERANTE
        """
        self.recognition_stats['total_attempts'] += 1

        # Verificar se h√° usu√°rios no banco
        if not self.facial_database:
            self.recognition_stats['failed_auth'] += 1
            return {
                "authenticated": False,
                "user": None,
                "confidence": 0.0,
                "message": "‚ö†Ô∏è Nenhum usu√°rio cadastrado no sistema",
                "timestamp": self.get_current_timestamp()
            }

        # Decodificar imagem
        frame = self._decode_base64_image(image_data)
        if frame is None:
            self.recognition_stats['failed_auth'] += 1
            return self._error_response("Dados de imagem inv√°lidos")

        # Detectar rosto
        face_data = self._detect_face(frame)
        if not face_data:
            self.recognition_stats['failed_auth'] += 1
            return self._error_response("Nenhum rosto detectado - aproxime-se da c√¢mera")

        # Extrair regi√£o do rosto
        face_area = face_data["facial_area"]
        x, y, w, h = face_area['x'], face_area['y'], face_area['w'], face_area['h']

        # ‚úÖ VALIDA√á√ÉO DE TAMANHO MAIS TOLERANTE
        if w < self._model_config.MIN_FACE_SIZE[0] or h < self._model_config.MIN_FACE_SIZE[1]:
            self.recognition_stats['failed_auth'] += 1
            return self._error_response("Rosto muito pequeno - aproxime-se mais da c√¢mera")

        face_roi = frame[y:y+h, x:x+w]

        # ‚úÖ VALIDA√á√ÉO DE QUALIDADE MAIS TOLERANTE
        is_quality_ok, quality_msg = self._validate_face_quality(face_roi)
        if not is_quality_ok:
            self.recognition_stats['quality_rejections'] += 1
            # ‚úÖ MESMO COM QUALIDADE BAIXA, TENTA RECONHECER
            logger.info(f"‚ö†Ô∏è Qualidade baixa, mas tentando reconhecer: {quality_msg}")

        # Reconhecer rosto
        user, distance, confidence = self._recognize_face(face_roi)

        if user and confidence and confidence > self._model_config.MIN_CONFIDENCE_THRESHOLD:
            self.recognition_stats['successful_auth'] += 1

            logger.info(f"‚úÖ AUTH SUCCESS: {user} - Dist: {distance:.3f} - Conf: {confidence:.3f}")

            return self._success_response(user, confidence, distance)
        else:
            self.recognition_stats['failed_auth'] += 1

            if user:  # Usu√°rio encontrado mas confian√ßa baixa
                logger.info(f"‚ö†Ô∏è AUTH REJECTED: {user} - Confian√ßa baixa: {confidence:.3f}")
            else:
                logger.info(f"‚ùå AUTH FAILED: Usu√°rio n√£o reconhecido")

            return self._rejection_response()

    def _success_response(self, user: str, confidence: float, distance: float) -> Dict[str, Any]:
        """Resposta para autentica√ß√£o bem-sucedida"""
        user_data = self.facial_database[user]['info']

        return {
            "authenticated": True,
            "user": user,
            "user_details": user_data,
            "confidence": round(confidence, 4),
            "distance": round(distance, 4),
            "message": f"Bem-vindo(a), {user_data['nome']}!",
            "timestamp": self.get_current_timestamp(),
            "stats": {
                "total_attempts": self.recognition_stats['total_attempts'],
                "success_rate": round(self.recognition_stats['successful_auth'] / self.recognition_stats['total_attempts'] * 100, 1)
            }
        }

    def _rejection_response(self) -> Dict[str, Any]:
        """Resposta para usu√°rio n√£o reconhecido"""
        return {
            "authenticated": False,
            "user": None,
            "confidence": 0.0,
            "message": "Usu√°rio n√£o reconhecido - tente novamente com melhor ilumina√ß√£o",
            "timestamp": self.get_current_timestamp(),
            "stats": {
                "total_attempts": self.recognition_stats['total_attempts'],
                "success_rate": round(self.recognition_stats['successful_auth'] / self.recognition_stats['total_attempts'] * 100, 1)
            }
        }

    def _error_response(self, message: str) -> Dict[str, Any]:
        """Resposta para erro no processamento"""
        return {
            "authenticated": False,
            "user": None,
            "confidence": 0.0,
            "message": message,
            "timestamp": self.get_current_timestamp()
        }

    # ... (restante dos m√©todos mantidos igual) ...

    def get_database_status(self) -> Dict[str, Any]:
        """Status do banco de dados"""
        user_count = len(self.facial_database)
        total_embeddings = sum(len(user_data['embeddings']) for user_data in self.facial_database.values())

        success_rate = 0
        if self.recognition_stats['total_attempts'] > 0:
            success_rate = round(self.recognition_stats['successful_auth'] / self.recognition_stats['total_attempts'] * 100, 1)

        return {
            "status": "loaded" if self.facial_database else "empty",
            "user_count": user_count,
            "total_embeddings": total_embeddings,
            "avg_embeddings_per_user": round(total_embeddings / user_count, 1) if user_count > 0 else 0,
            "last_update": self.last_update,
            "monitoring_active": self.database_monitor.running if hasattr(self, 'database_monitor') else False,
            "database_type": "PostgreSQL",
            "model": self._model_config.MODEL_NAME,
            "embedding_dimension": self._model_config.EMBEDDING_DIMENSION,
            "threshold": self._model_config.DISTANCE_THRESHOLD,
            "recognition_stats": {
                "total_attempts": self.recognition_stats['total_attempts'],
                "successful_auth": self.recognition_stats['successful_auth'],
                "failed_auth": self.recognition_stats['failed_auth'],
                "quality_rejections": self.recognition_stats['quality_rejections'],
                "success_rate": f"{success_rate}%"
            }
        }

    def reload_database(self) -> Tuple[bool, str]:
        """Recarrega banco de dados"""
        success = self.load_facial_database()
        if success:
            status = self.get_database_status()
            message = (f"Database recarregado - {status['user_count']} usu√°rios, "
                      f"{status['total_embeddings']} embeddings")

            logger.info(f"üîÑ {message}")

            return True, message
        else:
            return False, "Falha no recarregamento do banco"

    def initialize(self) -> bool:
        """Inicializa o servi√ßo com configura√ß√£o TOLERANTE"""
        logger.info("üîß Inicializando Servi√ßo de Reconhecimento Facial (Modo Tolerante)...")
        logger.info(f"üéØ Modelo: {self._model_config.MODEL_NAME}")
        logger.info(f"üìä Dimens√£o: {self._model_config.EMBEDDING_DIMENSION}")
        logger.info(f"üéØ Threshold: {self._model_config.DISTANCE_THRESHOLD} (Tolerante)")
        logger.info(f"üîç Detector: {self._model_config.DETECTOR_BACKEND} (Tolerante)")

        if not self._create_table_if_not_exists():
            logger.error("‚ùå Falha na cria√ß√£o da tabela")
            return False

        trigger_success = self._setup_database_triggers()
        db_success = self.load_facial_database()
        monitor_success = self.database_monitor.start_monitoring()

        if db_success:
            status = self.get_database_status()
            logger.info(f"‚úÖ Database carregado: {status['user_count']} usu√°rios, {status['total_embeddings']} embeddings")

            if trigger_success and monitor_success:
                logger.info("üéØ Monitoramento em tempo real: ATIVO")
            else:
                logger.warning("‚ö†Ô∏è Monitoramento em tempo real: LIMITADO")

        return db_success

    def cleanup(self):
        """Limpeza do servi√ßo"""
        if hasattr(self, 'database_monitor'):
            self.database_monitor.stop_monitoring()
        logger.info("üßπ Face recognition service cleaned up")

    @staticmethod
    def get_current_timestamp() -> str:
        """Retorna timestamp atual formatado"""
        return datetime.now().isoformat(sep=' ', timespec='seconds')